{
  "name": "mnist_classification_pipeline",
  "status": "success",
  "created_at": "2025-06-14T10:42:20.076368",
  "last_updated": "2025-06-14T10:42:20.076524",
  "metadata": {
    "name": "mnist_classification_pipeline",
    "description": "MNIST digit classification using PyTorch",
    "version": "1.0",
    "author": "ML Team",
    "tags": [
      "computer-vision",
      "classification",
      "mnist",
      "pytorch"
    ]
  },
  "tasks": {
    "fetch_mnist_data": {
      "name": "fetch_mnist_data",
      "command": "python /tmp/mnist_test_z3482m84/scripts/fetch_mnist.py --output /tmp/mnist_test_z3482m84/data/raw/",
      "depends_on": [],
      "retry_count": 0,
      "timeout": 300,
      "working_dir": null,
      "environment": {},
      "status": "success",
      "current_attempt": 0,
      "error_message": null,
      "result": {
        "exit_code": 0,
        "stdout": "âœ… sklearn imported successfully\nğŸ“¥ Starting MNIST data fetch...\nğŸ“¥ Fetching MNIST data from sklearn...\nğŸ“Š MNIST data loaded:\n   Images shape: (70000, 784)\n   Labels shape: (70000,)\n   Classes: [0 1 2 3 4 5 6 7 8 9]\nğŸ“ˆ Data split:\n   Training: 60000 samples\n   Testing: 10000 samples\nğŸ’¾ Data saved to /tmp/mnist_test_z3482m84/data/raw\n   X_train.npy: (60000, 784)\n   y_train.npy: (60000,)\n   X_test.npy: (10000, 784)\n   y_test.npy: (10000,)\n   metadata.json: Dataset information\nğŸ‰ MNIST data fetch completed successfully!\n",
        "stderr": "/home/therrshan/gitrepos/ml-orchestrator/.venv/lib/python3.8/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n  warn(\n",
        "execution_time": 12.843668,
        "start_time": "2025-06-14T10:41:49.058466",
        "end_time": "2025-06-14T10:42:01.902134"
      }
    },
    "preprocess_data": {
      "name": "preprocess_data",
      "command": "python /tmp/mnist_test_z3482m84/scripts/preprocess_mnist.py --input /tmp/mnist_test_z3482m84/data/raw/ --output /tmp/mnist_test_z3482m84/data/processed/",
      "depends_on": [
        "fetch_mnist_data"
      ],
      "retry_count": 0,
      "timeout": 300,
      "working_dir": null,
      "environment": {},
      "status": "success",
      "current_attempt": 0,
      "error_message": null,
      "result": {
        "exit_code": 0,
        "stdout": "âš™ï¸ Starting MNIST preprocessing...\nâš™ï¸ Preprocessing MNIST data...\nğŸ“‚ Loading raw data...\nğŸ“Š Loaded data shapes:\n   X_train: (60000, 784)\n   y_train: (60000,)\n   X_test: (10000, 784)\n   y_test: (10000,)\nğŸ”„ Reshaped for CNN:\n   X_train: (60000, 28, 28)\n   X_test: (10000, 28, 28)\nğŸ“ˆ Train/Validation split:\n   Training: 54000 samples\n   Validation: 6000 samples\n   Test: 10000 samples\nğŸ’¾ Processed data saved:\n   train.npz: 54000 samples\n   validation.npz: 6000 samples\n   test.npz: 10000 samples\n   preprocessing_info.json: Metadata\nğŸ“Š Class distribution in training set:\n   Digit 0: 5299 samples\n   Digit 1: 6088 samples\n   Digit 2: 5386 samples\n   Digit 3: 5542 samples\n   Digit 4: 5262 samples\n   Digit 5: 4870 samples\n   Digit 6: 5338 samples\n   Digit 7: 5632 samples\n   Digit 8: 5266 samples\n   Digit 9: 5317 samples\nğŸ‰ MNIST preprocessing completed successfully!\n",
        "stderr": "",
        "execution_time": 3.347708,
        "start_time": "2025-06-14T10:42:02.003803",
        "end_time": "2025-06-14T10:42:05.351511"
      }
    },
    "train_pytorch_model": {
      "name": "train_pytorch_model",
      "command": "python /tmp/mnist_test_z3482m84/scripts/train_pytorch_mnist.py --data /tmp/mnist_test_z3482m84/data/processed/ --model /tmp/mnist_test_z3482m84/models/mnist_pytorch.pth --epochs 5",
      "depends_on": [
        "preprocess_data"
      ],
      "retry_count": 1,
      "timeout": 600,
      "working_dir": null,
      "environment": {
        "BATCH_SIZE": "64",
        "LEARNING_RATE": "0.001"
      },
      "status": "success",
      "current_attempt": 0,
      "error_message": null,
      "result": {
        "exit_code": 0,
        "stdout": "âœ… PyTorch imported successfully\nğŸ¤– Starting PyTorch MNIST training...\nğŸ“Š Parameters:\n   Epochs: 5\n   Batch size: 64\n   Learning rate: 0.001\nğŸ“‚ Loaded training data: (54000, 28, 28)\nğŸ“‚ Loaded validation data: (6000, 28, 28)\nğŸ”„ Created data loaders:\n   Train batches: 844\n   Validation batches: 94\nğŸ—ï¸  Created model with 130890 parameters\nğŸ–¥ï¸  Training on device: cuda\nğŸ‹ï¸  Starting training for 5 epochs...\nEpoch 1/5, Batch 0/844, Loss: 2.3020\nEpoch 1/5, Batch 100/844, Loss: 0.3716\nEpoch 1/5, Batch 200/844, Loss: 0.3129\nEpoch 1/5, Batch 300/844, Loss: 0.1286\nEpoch 1/5, Batch 400/844, Loss: 0.1012\nEpoch 1/5, Batch 500/844, Loss: 0.1672\nEpoch 1/5, Batch 600/844, Loss: 0.1198\nEpoch 1/5, Batch 700/844, Loss: 0.0984\nEpoch 1/5, Batch 800/844, Loss: 0.0441\nEpoch 1/5:\n  Train Loss: 0.3093, Train Acc: 90.18%\n  Val Loss: 0.0637, Val Acc: 98.18%\n\nEpoch 2/5, Batch 0/844, Loss: 0.0532\nEpoch 2/5, Batch 100/844, Loss: 0.0897\nEpoch 2/5, Batch 200/844, Loss: 0.0983\nEpoch 2/5, Batch 300/844, Loss: 0.0275\nEpoch 2/5, Batch 400/844, Loss: 0.1384\nEpoch 2/5, Batch 500/844, Loss: 0.0403\nEpoch 2/5, Batch 600/844, Loss: 0.1963\nEpoch 2/5, Batch 700/844, Loss: 0.0795\nEpoch 2/5, Batch 800/844, Loss: 0.0328\nEpoch 2/5:\n  Train Loss: 0.0949, Train Acc: 97.31%\n  Val Loss: 0.0456, Val Acc: 98.73%\n\nEpoch 3/5, Batch 0/844, Loss: 0.0601\nEpoch 3/5, Batch 100/844, Loss: 0.0602\nEpoch 3/5, Batch 200/844, Loss: 0.0874\nEpoch 3/5, Batch 300/844, Loss: 0.0220\nEpoch 3/5, Batch 400/844, Loss: 0.0810\nEpoch 3/5, Batch 500/844, Loss: 0.0232\nEpoch 3/5, Batch 600/844, Loss: 0.1954\nEpoch 3/5, Batch 700/844, Loss: 0.0526\nEpoch 3/5, Batch 800/844, Loss: 0.1026\nEpoch 3/5:\n  Train Loss: 0.0691, Train Acc: 98.00%\n  Val Loss: 0.0429, Val Acc: 98.73%\n\nEpoch 4/5, Batch 0/844, Loss: 0.0243\nEpoch 4/5, Batch 100/844, Loss: 0.0345\nEpoch 4/5, Batch 200/844, Loss: 0.0845\nEpoch 4/5, Batch 300/844, Loss: 0.0046\nEpoch 4/5, Batch 400/844, Loss: 0.1138\nEpoch 4/5, Batch 500/844, Loss: 0.0275\nEpoch 4/5, Batch 600/844, Loss: 0.0899\nEpoch 4/5, Batch 700/844, Loss: 0.0508\nEpoch 4/5, Batch 800/844, Loss: 0.1267\nEpoch 4/5:\n  Train Loss: 0.0535, Train Acc: 98.43%\n  Val Loss: 0.0383, Val Acc: 98.88%\n\nEpoch 5/5, Batch 0/844, Loss: 0.0286\nEpoch 5/5, Batch 100/844, Loss: 0.0345\nEpoch 5/5, Batch 200/844, Loss: 0.0439\nEpoch 5/5, Batch 300/844, Loss: 0.0967\nEpoch 5/5, Batch 400/844, Loss: 0.1055\nEpoch 5/5, Batch 500/844, Loss: 0.0532\nEpoch 5/5, Batch 600/844, Loss: 0.0438\nEpoch 5/5, Batch 700/844, Loss: 0.0723\nEpoch 5/5, Batch 800/844, Loss: 0.0150\nEpoch 5/5:\n  Train Loss: 0.0473, Train Acc: 98.62%\n  Val Loss: 0.0384, Val Acc: 98.78%\n\nğŸ’¾ Model saved:\n   Model: /tmp/mnist_test_z3482m84/models/mnist_pytorch.pth\n   Metadata: /tmp/mnist_test_z3482m84/models/mnist_pytorch.json\nğŸ‰ Training completed successfully!\nğŸ“ˆ Final validation accuracy: 98.78%\n",
        "stderr": "",
        "execution_time": 12.143079,
        "start_time": "2025-06-14T10:42:05.453250",
        "end_time": "2025-06-14T10:42:17.596329"
      }
    },
    "evaluate_model": {
      "name": "evaluate_model",
      "command": "python /tmp/mnist_test_z3482m84/scripts/evaluate_pytorch_mnist.py --model /tmp/mnist_test_z3482m84/models/mnist_pytorch.pth --test /tmp/mnist_test_z3482m84/data/processed/test.npz --output /tmp/mnist_test_z3482m84/results/",
      "depends_on": [
        "train_pytorch_model"
      ],
      "retry_count": 0,
      "timeout": 300,
      "working_dir": null,
      "environment": {},
      "status": "success",
      "current_attempt": 0,
      "error_message": null,
      "result": {
        "exit_code": 0,
        "stdout": "âœ… PyTorch and sklearn imported successfully\nğŸ§ª Starting PyTorch MNIST evaluation...\nğŸ“‚ Loading model from /tmp/mnist_test_z3482m84/models/mnist_pytorch.pth\nâœ… Model loaded successfully\nğŸ“‚ Loading test data from /tmp/mnist_test_z3482m84/data/processed/test.npz\nğŸ“Š Test data shape: (10000, 28, 28)\nğŸ“Š Test labels shape: (10000,)\nğŸ§ª Evaluating model on test data...\nğŸ“ˆ Test Accuracy: 0.9899 (98.99%)\nğŸ’¾ Results saved to /tmp/mnist_test_z3482m84/results\n   evaluation_results.json: Detailed metrics\n   predictions.npz: Predictions and probabilities\n\n==================================================\nğŸ“Š EVALUATION SUMMARY\n==================================================\nOverall Accuracy: 0.9899\nMacro Avg Precision: 0.9900\nMacro Avg Recall: 0.9897\nMacro Avg F1-Score: 0.9898\nAverage Confidence: 0.9920\n\nğŸ“ˆ Per-Class Accuracy:\n   Digit 0: 0.9939 (99.4%)\n   Digit 1: 0.9938 (99.4%)\n   Digit 2: 0.9922 (99.2%)\n   Digit 3: 0.9980 (99.8%)\n   Digit 4: 0.9847 (98.5%)\n   Digit 5: 0.9809 (98.1%)\n   Digit 6: 0.9885 (98.9%)\n   Digit 7: 0.9912 (99.1%)\n   Digit 8: 0.9836 (98.4%)\n   Digit 9: 0.9901 (99.0%)\n\nğŸ† Best performing digit: 3 (0.9980)\nğŸ” Worst performing digit: 5 (0.9809)\n\nğŸ‰ Evaluation completed successfully!\n",
        "stderr": "/tmp/mnist_test_z3482m84/scripts/evaluate_pytorch_mnist.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(model_path, map_location='cpu')\n",
        "execution_time": 2.053276,
        "start_time": "2025-06-14T10:42:17.698036",
        "end_time": "2025-06-14T10:42:19.751312"
      }
    },
    "generate_report": {
      "name": "generate_report",
      "command": "python /tmp/mnist_test_z3482m84/scripts/create_mnist_report.py --results /tmp/mnist_test_z3482m84/results/ --output /tmp/mnist_test_z3482m84/reports/mnist_report.html",
      "depends_on": [
        "evaluate_model"
      ],
      "retry_count": 0,
      "timeout": 120,
      "working_dir": null,
      "environment": {},
      "status": "success",
      "current_attempt": 0,
      "error_message": null,
      "result": {
        "exit_code": 0,
        "stdout": "ğŸ“Š Generating MNIST classification report...\nğŸ‰ Report generated successfully!\nğŸ“„ HTML report: /tmp/mnist_test_z3482m84/reports/mnist_report.html\nğŸŒ Open in browser: file:///tmp/mnist_test_z3482m84/reports/mnist_report.html\n",
        "stderr": "",
        "execution_time": 0.121848,
        "start_time": "2025-06-14T10:42:19.852963",
        "end_time": "2025-06-14T10:42:19.974811"
      }
    }
  },
  "execution_history": [],
  "completed_tasks": [
    "train_pytorch_model",
    "generate_report",
    "preprocess_data",
    "evaluate_model",
    "fetch_mnist_data"
  ],
  "failed_tasks": []
}